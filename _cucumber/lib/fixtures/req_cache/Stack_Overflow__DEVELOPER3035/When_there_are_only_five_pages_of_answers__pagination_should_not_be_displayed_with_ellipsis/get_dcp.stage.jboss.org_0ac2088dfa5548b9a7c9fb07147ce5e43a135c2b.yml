---
:scope: 
:url: https://dcp.stage.jboss.org/v2/rest/search/stackoverflow/?field=sys_url_view&field=sys_title&field=is_answered&field=author&field=sys_tags&field=answers&field=sys_created&field=view_count&field=answer_count&field=down_vote_count&field=up_vote_count&field=sys_content&from=0&product=&project=&query=&query_highlight=true&size=10&size10=true
:body: ''
:status: 200
:method: get
:headers:
  Server: Apache-Coyote/1.1
  Pragma: No-cache
  Cache-Control: no-cache
  Expires: Wed, 31 Dec 1969 19:00:00 EST
  Access-Control-Allow-Origin: https://developers-pr.stage.redhat.com
  Content-Type: application/json
  Date: Fri, 13 Jan 2017 11:54:53 GMT
  Connection: close
  Set-Cookie: BigIP.dcp.stage.jboss.org=rd221o00000000000000000000ffff0a196a37o8080;
    path=/
:content: '{"uuid":"9c41ab0d-b33c-4652-a037-b9fa1ca024f5","took":1,"timed_out":false,"_shards":{"total":6,"successful":6,"failed":0},"hits":{"total":50,"max_score":null,"hits":[{"_index":"data_stackoverflow_question","_type":"stackoverflow_question","_id":"41632389","_score":1.0,"_source":{"source":"stackoverflow_question","space_key":"openshift","sys_id":"41632389","sys_type":"stackoverflow_thread","answer_count":"0","sys_updated":"2017-01-13T05:33:39.531-05:00","sys_id":"stackoverflow_question-41632389","sys_url_view":"http://stackoverflow.com/questions/41632389/openshift-disk-quota-exceeded","sys_content_id":"41632389","last_activity":"1484303251000","down_vote_count":"0","sys_content_provider":"stackoverflow","sys_content_content-type":"text/plain","owner":{"profile_image":"https://www.gravatar.com/avatar/ebf72f3e9baf847980ed8355216db133?s=128&d=identicon&r=PG&f=1","user_type":"registered","user_id":6561309,"link":"http://stackoverflow.com/users/6561309/richard","reputation":410,"display_name":"Richard","accept_rate":29},"sys_content_plaintext":"I
  have a Wildfly Server running on OpenShift (free). I have just started getting the
  following: Disk quota exceeded However, when I run: quota -s I get: Disk quotas
  for user 578e6de37838e104d7098028 (uid 4589): Filesystem blocks quota limit grace
  files quota limit grace /dev/mapper/EBSStore01-user_home01 887M 0 1024M 7844 0 80000
  As you can see, I am using 877M of 1024M. Why is it complaining that the disk quota
  has exceeded? As far as I can see I still have 147M left. What can I do to fee up
  space? I don''t want to have to pay while I am still in development. I have already
  done rhc app-tidy <appname> , which did free some space. Any advise appreciated.","sys_content_type":"stackoverflow_question","author":"Richard-6561309","sys_tags":["openshift"],"sys_title":"Stubbed
  Title One","tags":["openshift"],"sys_content":"<p>I have a Wildfly Server
  running on OpenShift (free).</p>\n\n<p>I have just started getting the following:    </p>\n\n<blockquote>\n  <p>Disk
  quota exceeded</p>\n</blockquote>\n\n<p>However, when I run:</p>\n\n<pre><code>quota
  -s\n</code></pre>\n\n<p>I get:</p>\n\n<blockquote>\n<pre><code>Disk quotas for user
  578e6de37838e104d7098028 (uid 4589): \n     Filesystem  blocks   quota   limit   grace   files   quota   limit   grace\n/dev/mapper/EBSStore01-user_home01\n                   887M       0   1024M            7844       0   80000\n</code></pre>\n</blockquote>\n\n<p>As
  you can see, I am using 877M of 1024M. Why is it complaining that the disk quota
  has exceeded? As far as I can see I still have 147M left.</p>\n\n<p>What can I do
  to fee up space? I don''t want to have to pay while I am still in development. I
  have already done <code>rhc app-tidy &lt;appname&gt;</code>, which did free some
  space.</p>\n\n<p>Any advise appreciated.</p>\n","user_id":"6561309","sys_created":"1484303251000","is_answered":"false","view_count":"4","up_vote_count":"0"},"sort":[1484303251000,1.0]},{"_index":"data_stackoverflow_question","_type":"stackoverflow_question","_id":"41632190","_score":1.0,"_source":{"source":"stackoverflow_question","space_key":"openshift","sys_id":"41632190","sys_type":"stackoverflow_thread","answer_count":"0","sys_updated":"2017-01-13T05:33:38.444-05:00","sys_id":"stackoverflow_question-41632190","sys_url_view":"http://stackoverflow.com/questions/41632190/automatically-deploy-feature-branches-in-openshift","sys_content_id":"41632190","last_activity":"1484302631000","down_vote_count":"0","sys_content_provider":"stackoverflow","sys_content_content-type":"text/plain","owner":{"profile_image":"https://www.gravatar.com/avatar/53a09bb289b100111e13440ba3324eb3?s=128&d=identicon&r=PG","user_type":"registered","user_id":172132,"link":"http://stackoverflow.com/users/172132/cimnine","reputation":1487,"display_name":"cimnine","accept_rate":64},"sys_content_plaintext":"The
  projects I work with are all Git based, hosted Github and follow a simple development
  workflow (inspired by git-flow ): We create a feature branch for all our changes
  We then create a pull-request for review Eventually merge the change to master .
  We don''t do releases and versions per-se as we deploy changes immediately, hence
  master is always what''s on production. Every project is dockerized, i.e. there
  is a Dockerfile in the root of the project that contains all the dependencies this
  project needs to run. Most of the time, there''s also a docker-compose.yaml file
  for development. We have an OpenShift cluster, where we run the applications. Currently,
  there is a Github hook which triggers a build & re-deploy when something is merged
  to master. We currently build with the source-to-image approach, but this is not
  cast in stone. What I would like to have is a simple way to automatically deploy
  feature branches to some staging environment: First-time push of feature_branch
  to GitHub triggers some hook and calls OpenShift (or the OpenShift Jenkins ). OpenShift
  automatically recognises the new branch, kick''s off the CI and deploys the result
  to a staging ''environment'', so that it becomes reachable as feature_branch-app.openshift.cluster
  . (*) For every push to that branch, the previous step is repeated. Optional (aka
  Bonus): Once a feature branch gets merged to master and removed from GitHub, the
  corresponding resources are getting freed. (*) The exact structure of the URL may
  differ, but it must contain the branch''s name in a consistent manner. Also, assume
  that the branch names are always legal ''domain names'', i.e. they are only made
  up of digits ( 0-9 ), letters ( a-z ), hyphens ( - ) and underscores ( _ ). Assume
  unlimited control over the OpenShift cluster (i.e. all features that it offers can
  be used).","sys_content_type":"stackoverflow_question","author":"cimnine-172132","sys_tags":["git","continuous-integration","openshift","workflow","continuous-deployment"],"sys_title":"Stubbed
  Title Two","tags":["git","continuous-integration","openshift","workflow","continuous-deployment"],"sys_content":"<p>The
  projects I work with are all Git based, hosted Github and follow a simple development
  workflow (inspired by <code>git-flow</code>):</p>\n\n<ol>\n<li>We create a <em>feature
  branch</em> for all our changes</li>\n<li>We then create a pull-request for review</li>\n<li>Eventually
  merge the change to <em>master</em>.</li>\n</ol>\n\n<p>We don''t do releases and
  versions per-se as we deploy changes immediately, hence <em>master</em> is always
  what''s on production.</p>\n\n<p>Every project is dockerized, i.e. there is a <code>Dockerfile</code>
  in the root of the project that contains all the dependencies this project needs
  to run. Most of the time, there''s also a <code>docker-compose.yaml</code> file
  for development.</p>\n\n<p>We have an OpenShift cluster, where we run the applications.
  Currently, there is a Github hook which triggers a build &amp; re-deploy when something
  is merged to master. We currently build with the <a href=\"https://github.com/openshift/source-to-image\"
  rel=\"nofollow noreferrer\">source-to-image</a> approach, but this is not cast in
  stone.</p>\n\n<p>What I would like to have is a simple way to automatically deploy
  feature branches to some staging environment:</p>\n\n<ol>\n<li>First-time push of
  <em>feature_branch</em> to GitHub triggers some hook and calls OpenShift (or the
  <a href=\"https://github.com/openshift/jenkins\" rel=\"nofollow noreferrer\">OpenShift
  Jenkins</a>).</li>\n<li>OpenShift automatically recognises the new branch, kick''s
  off the CI and deploys the result to a staging ''environment'', so that it becomes
  reachable as <code>feature_branch-app.openshift.cluster</code>. (*)</li>\n<li>For
  every push to that branch, the previous step is repeated.</li>\n<li>Optional (aka
  Bonus): Once a feature branch gets merged to <em>master</em> and removed from GitHub,
  the corresponding resources are getting freed.</li>\n</ol>\n\n<p>(*) The exact structure
  of the URL may differ, but it must contain the branch''s name in a consistent manner.
  Also, assume that the branch names are always legal ''domain names'', i.e. they
  are only made up of digits (<code>0-9</code>), letters (<code>a-z</code>), hyphens
  (<code>-</code>) and underscores (<code>_</code>).</p>\n\n<p>Assume unlimited control
  over the OpenShift cluster (i.e. all features that it offers can be used).</p>\n","user_id":"172132","sys_created":"1484302631000","is_answered":"false","view_count":"4","up_vote_count":"0"},"sort":[1484302631000,1.0]},{"_index":"data_stackoverflow_question","_type":"stackoverflow_question","_id":"41632183","_score":1.0,"_source":{"source":"stackoverflow_question","space_key":"openshift","sys_id":"41632183","sys_type":"stackoverflow_thread","answer_count":"0","sys_updated":"2017-01-13T05:33:38.442-05:00","sys_id":"stackoverflow_question-41632183","sys_url_view":"http://stackoverflow.com/questions/41632183/app-to-get-openshift-route-url-and-certificate-key-pair","sys_content_id":"41632183","last_activity":"1484302599000","down_vote_count":"0","sys_content_provider":"stackoverflow","sys_content_content-type":"text/plain","owner":{"profile_image":"https://www.gravatar.com/avatar/a468694290fc76ee203f00107ad7a711?s=128&d=identicon&r=PG","user_type":"registered","user_id":782409,"link":"http://stackoverflow.com/users/782409/feng-xi","reputation":48,"display_name":"Feng
  Xi","accept_rate":95},"sys_content_plaintext":"I''m running my app in openshift.
  I''ve created a openshift https route. I''m wondering is there a way that my app
  can get the route https url and its certificate/key ? is there such an env I can
  use ? I''m using openshift-origin 1.4 Thanks","sys_content_type":"stackoverflow_question","author":"Feng
  Xi-782409","sys_tags":["openshift","openshift-origin"],"sys_title":"Stubbed
  Title Three","tags":["openshift","openshift-origin"],"sys_content":"<p>I''m
  running my app in openshift. I''ve created a openshift https route.</p>\n\n<p>I''m
  wondering is there a way that my app can get the route https url and its certificate/key
  ? is there such an env I can use ?</p>\n\n<p>I''m using openshift-origin 1.4</p>\n\n<ul>\n<li>Thanks</li>\n</ul>\n","user_id":"782409","sys_created":"1484302599000","is_answered":"false","view_count":"5","up_vote_count":"0"},"sort":[1484302599000,1.0]},{"_index":"data_stackoverflow_question","_type":"stackoverflow_question","_id":"41630830","_score":1.0,"_source":{"source":"stackoverflow_question","space_key":"redhat","sys_id":"41630830","answers":[{"owner":{"profile_image":"https://i.stack.imgur.com/uhHvv.jpg?s=128&g=1","user_type":"registered","user_id":285587,"link":"http://stackoverflow.com/users/285587/your-common-sense","reputation":113469,"display_name":"Your
  Common Sense","accept_rate":58},"comment_count":0,"is_accepted":false,"last_activity_date":"1484298459000","creation_date":"1484298459000","title":"Hosting
  an application on Red Hat Linux Server","body":"<p>Fedora and Red Hat are basically
  the same. So you can use the same documentation you were using for Fedora. In case
  you didn''t, you can google for Centos manuals also, as the latter is the same as
  well.</p>\n","answer_id":41630909,"question_id":41630830,"tags":[],"share_link":"http://stackoverflow.com/a/41630909","score":0,"down_vote_count":0,"up_vote_count":0}],"sys_type":"stackoverflow_thread","answer_count":"1","time_to_answer_mins":4.933333333333334,"sys_updated":"2017-01-13T04:07:48.503-05:00","sys_id":"stackoverflow_question-41630830","sys_url_view":"http://stackoverflow.com/questions/41630830/hosting-an-application-on-red-hat-linux-server","sys_content_id":"41630830","last_activity":"1484298459000","down_vote_count":"0","sys_content_provider":"stackoverflow","sys_content_content-type":"text/plain","owner":{"profile_image":"https://www.gravatar.com/avatar/7f6382c204dc2704398d709f831534c0?s=128&d=identicon&r=PG","user_type":"registered","user_id":2589917,"link":"http://stackoverflow.com/users/2589917/neha","reputation":1,"display_name":"neha"},"sys_content_plaintext":"I
  am using the Red Hat Linux sever for the first time and would like to know if there
  is any documentation available on the steps to host an application on it and about
  how to establish a connection to a MariaDB database. The game application is currently
  on Freeoda and I want to host it on the Red Hat Linux server. Thanks in advance.","sys_content_type":"stackoverflow_question","author":"neha-2589917","sys_tags":["linux","mariadb","redhat"],"sys_title":"Stubbed
  Title Four","tags":["linux","mariadb","redhat"],"sys_content":"<p>I
  am using the Red Hat Linux sever for the first time and would like to know if there
  is any documentation available on the steps to host an application on it and about
  how to establish a connection to a MariaDB database. The game application is currently
  on Freeoda and I want to host it on the Red Hat Linux server. </p>\n\n<p>Thanks
  in advance.</p>\n","user_id":"2589917","sys_created":"1484298163000","is_answered":"false","view_count":"4","up_vote_count":"0"},"sort":[1484298163000,1.0]},{"_index":"data_stackoverflow_question","_type":"stackoverflow_question","_id":"41630006","_score":1.0,"_source":{"source":"stackoverflow_question","space_key":"jboss7.x","sys_id":"41630006","sys_type":"stackoverflow_thread","answer_count":"0","sys_updated":"2017-01-13T04:31:18.428-05:00","sys_id":"stackoverflow_question-41630006","sys_url_view":"http://stackoverflow.com/questions/41630006/kodo-on-jboss-7","sys_content_id":"41630006","last_activity":"1484298969000","down_vote_count":"0","sys_content_provider":"stackoverflow","sys_content_content-type":"text/plain","owner":{"profile_image":"https://www.gravatar.com/avatar/a8f90d3750ed1737ad03df1eebf7b0c5?s=128&d=identicon&r=PG","user_type":"registered","user_id":353497,"link":"http://stackoverflow.com/users/353497/ameya","reputation":566,"display_name":"Ameya","accept_rate":61},"sys_content_plaintext":"we
  are looking to run replace Oracle Kodo persistence (JPA) framework as it does not
  build with JDK 1.8 and JBoss EAP 7 throwing error in maven build. Is there any official
  document supporting Kodo has been deprecated and would not work with JBoss EAP 7?
  I managed to only get the following reference link Please help me out with this
  issue, any input is appreciated.","sys_content_type":"stackoverflow_question","author":"Ameya-353497","sys_tags":["java","java-8","jboss7.x","kodo"],"sys_title":"Stubbed
  Title Five","tags":["java","java-8","jboss7.x","kodo"],"sys_content":"<p>we are
  looking to run replace Oracle Kodo persistence (JPA) framework as it does not build
  with JDK 1.8 and JBoss EAP 7 throwing error in maven build. Is there any official
  document supporting Kodo has been deprecated and would not work with JBoss EAP 7?
  I managed to only get the following reference <a href=\"https://docs.oracle.com/cd/E13189_01/kodo/docs324/j2ee_tutorial_jca_installation.html\"
  rel=\"nofollow noreferrer\">link</a> Please help me out with this issue, any input
  is appreciated.</p>\n","user_id":"353497","sys_created":"1484294988000","is_answered":"false","view_count":"11","up_vote_count":"0"},"sort":[1484294988000,1.0]},{"_index":"data_stackoverflow_question","_type":"stackoverflow_question","_id":"41627923","_score":1.0,"_source":{"source":"stackoverflow_question","space_key":"openshift","sys_id":"41627923","sys_type":"stackoverflow_thread","answer_count":"0","sys_updated":"2017-01-13T01:33:14.484-05:00","sys_id":"stackoverflow_question-41627923","sys_url_view":"http://stackoverflow.com/questions/41627923/openshift-image-change-trigger-across-clusters","sys_content_id":"41627923","last_activity":"1484285446000","down_vote_count":"0","sys_content_provider":"stackoverflow","sys_content_content-type":"text/plain","owner":{"profile_image":"https://www.gravatar.com/avatar/441fceb8100170ead5cd97ace7817cc2?s=128&d=identicon&r=PG&f=1","user_type":"registered","user_id":7413047,"link":"http://stackoverflow.com/users/7413047/luke-h","reputation":1,"display_name":"luke-h"},"sys_content_plaintext":"There''s
  a lot of material out there that almost answers this but doesn''t quite get there
  (unless I''m not looking hard enough) which is why I''m reaching out here: We''re
  considering OpenShift and I''m trying to figure out if an image change trigger can
  fire based on an update to an image in another OpenShift cluster. e.g.: If I have
  a dev cluster and a test cluster, can it be set up so that an image stream on the
  test cluster receives a notification from the registry on the dev cluster, like
  an image being pushed with the tag \":test\", and start deploying it straight away?
  (purely an example - I realise in reality dev/test are often the same cluster anyway)
  If so, is there a particular recommended way to do this across clusters, and is
  there any more detail on it available? Have listed the material I''ve looked at
  so far below on this. Thanks! The general tagging approach is described here but
  in the context of one cluster instead of multiple: rhelblog.redhat.com/2016/04/08/continuous-delivery-deployment-with-openshift-enterprise/
  Completely external registries like Docker Hub can''t do this but can be polled
  for changes (but I''m trying to see if the native notifications can be used rather
  than polling) I know there''s other ways to do this like using deployment hooks
  or Jenkins processes to run commands to push images across clusters, but I''m wondering
  if it can be done purely using image tagging and change triggers. The documentation
  suggests having a common shared registry is possible which would enable this: \"Clusters
  can only share a registry if the OpenShift Container Platform internal image registry
  is exposed via a route.\" https://docs.openshift.com/container-platform/3.3/dev_guide/application_lifecycle/promoting_applications.html
  ..but doesn''t delve into it any further than that. I''ve also come across a discussion
  that spoke of having separate registries on each cluster, but using the same backing
  storage: https://lists.openshift.redhat.com/openshift-archives/users/2016-March/msg00131.html","sys_content_type":"stackoverflow_question","author":"luke-h-7413047","sys_tags":["openshift","openshift-origin"],"sys_title":"Stubbed
  Title Six","tags":["openshift","openshift-origin"],"sys_content":"<p>There''s
  a lot of material out there that <em>almost</em> answers this but doesn''t quite
  get there (unless I''m not looking hard enough) which is why I''m reaching out here:</p>\n\n<p>We''re
  considering OpenShift and I''m trying to figure out if an image change trigger can
  fire based on an update to an image in another OpenShift cluster. e.g.: If I have
  a dev cluster and a test cluster, can it be set up so that an image stream on the
  test cluster receives a notification from the registry on the dev cluster, like
  an image being pushed with the tag \":test\", and start deploying it straight away?</p>\n\n<p>(purely
  an example - I realise in reality dev/test are often the same cluster anyway)</p>\n\n<p>If
  so, is there a particular recommended way to do this across clusters, and is there
  any more detail on it available?</p>\n\n<p>Have listed the material I''ve looked
  at so far below on this.</p>\n\n<p>Thanks!</p>\n\n<ul>\n<li>The general tagging
  approach is described here but in the context of one cluster instead of multiple:\nrhelblog.redhat.com/2016/04/08/continuous-delivery-deployment-with-openshift-enterprise/</li>\n<li>Completely
  external registries like Docker Hub can''t do this but can be polled for changes
  (but I''m trying to see if the native notifications can be used rather than polling)</li>\n<li>I
  know there''s other ways to do this like using deployment hooks or Jenkins processes
  to run commands to push images across clusters, but I''m wondering if it can be
  done purely using image tagging and change triggers. </li>\n<li>The documentation
  suggests having a common shared registry is possible which would enable this: \n\n<blockquote>\n  <p>\"Clusters
  can only share a registry if the OpenShift Container Platform internal image registry
  is exposed via a route.\" <a href=\"https://docs.openshift.com/container-platform/3.3/dev_guide/application_lifecycle/promoting_applications.html\"
  rel=\"nofollow noreferrer\">https://docs.openshift.com/container-platform/3.3/dev_guide/application_lifecycle/promoting_applications.html</a>\n  ..but
  doesn''t delve into it any further than that.</p>\n  \n  <ul>\n  <li>I''ve also
  come across a discussion that spoke of having separate registries on each cluster,
  but using the same backing storage: <a href=\"https://lists.openshift.redhat.com/openshift-archives/users/2016-March/msg00131.html\"
  rel=\"nofollow noreferrer\">https://lists.openshift.redhat.com/openshift-archives/users/2016-March/msg00131.html</a></li>\n  </ul>\n</blockquote></li>\n</ul>\n","user_id":"7413047","sys_created":"1484285446000","is_answered":"false","view_count":"4","up_vote_count":"0"},"sort":[1484285446000,1.0]},{"_index":"data_stackoverflow_question","_type":"stackoverflow_question","_id":"41627785","_score":1.0,"_source":{"source":"stackoverflow_question","space_key":"jboss-eap-6","sys_id":"41627785","sys_type":"stackoverflow_thread","answer_count":"0","sys_updated":"2017-01-13T01:32:06.141-05:00","sys_id":"stackoverflow_question-41627785","sys_url_view":"http://stackoverflow.com/questions/41627785/javax-xml-ws-webserviceexception-could-not-find-service-named-service-in-wsdl","sys_content_id":"41627785","last_activity":"1484284538000","down_vote_count":"0","sys_content_provider":"stackoverflow","sys_content_content-type":"text/plain","owner":{"profile_image":"https://www.gravatar.com/avatar/735dce909be938aa6d393f33e614c54b?s=128&d=identicon&r=PG&f=1","user_type":"registered","user_id":4393263,"link":"http://stackoverflow.com/users/4393263/user4393263","reputation":1,"display_name":"user4393263"},"sys_content_plaintext":"I
  use JBoss EAP 6.3 and cxf 2.7.11 to call SOAP web service of another server, but
  got an error as the below: 23:50:02,805 ERROR [stderr] (http-/10.4.133.80:8080-1)
  javax.xml.ws.WebServiceException: Could not find service named CoreService in wsdl
  http://dev01.aaa.local:8080/core/core?wsdl 23:50:02,806 ERROR [stderr] (http-/10.4.133.80:8080-1)
  at org.apache.cxf.jaxws.ServiceImpl.initializePorts(ServiceImpl.java:161) 23:50:02,806
  ERROR [stderr] (http-/10.4.133.80:8080-1) at org.apache.cxf.jaxws.ServiceImpl.<init>(ServiceImpl.java:149)
  23:50:02,806 ERROR [stderr] (http-/10.4.133.80:8080-1) at org.jboss.wsf.stack.cxf.client.ProviderImpl$JBossWSServiceImpl.<init>(ProviderImpl.java:552)
  23:50:02,806 ERROR [stderr] (http-/10.4.133.80:8080-1) at org.jboss.wsf.stack.cxf.client.ProviderImpl.createServiceDelegate(ProviderImpl.java:247)
  23:50:02,807 ERROR [stderr] (http-/10.4.133.80:8080-1) at javax.xml.ws.Service.<init>(Service.java:57)
  23:50:02,807 ERROR [stderr] (http-/10.4.133.80:8080-1) at com.aaa.ws.core.CoreService.<init>(CoreService.java:42)
  The problem is this error does not happen on my local window machine (it is working
  well), but only happens on our linux server. This means the service name exists
  in the wsdl file. JBoss version is the same, and deployed the same war. I really
  don''t get what the cause of this issue is. Would be very gratefull for any help!","sys_content_type":"stackoverflow_question","author":"user4393263-4393263","sys_tags":["web-services","soap","jboss","wsdl","jboss-eap-6"],"sys_title":"Stubbed
  Title Seven","tags":["web-services","soap","jboss","wsdl","jboss-eap-6"],"sys_content":"<p>I
  use JBoss EAP 6.3 and cxf 2.7.11 to call SOAP web service of another server, but
  got an error as the below:</p>\n\n<pre><code>23:50:02,805 ERROR [stderr] (http-/10.4.133.80:8080-1)
  javax.xml.ws.WebServiceException: Could not find service named CoreService in wsdl
  http://dev01.aaa.local:8080/core/core?wsdl\n23:50:02,806 ERROR [stderr] (http-/10.4.133.80:8080-1)  at
  org.apache.cxf.jaxws.ServiceImpl.initializePorts(ServiceImpl.java:161)\n23:50:02,806
  ERROR [stderr] (http-/10.4.133.80:8080-1)  at org.apache.cxf.jaxws.ServiceImpl.&lt;init&gt;(ServiceImpl.java:149)\n23:50:02,806
  ERROR [stderr] (http-/10.4.133.80:8080-1)  at org.jboss.wsf.stack.cxf.client.ProviderImpl$JBossWSServiceImpl.&lt;init&gt;(ProviderImpl.java:552)\n23:50:02,806
  ERROR [stderr] (http-/10.4.133.80:8080-1)  at org.jboss.wsf.stack.cxf.client.ProviderImpl.createServiceDelegate(ProviderImpl.java:247)\n23:50:02,807
  ERROR [stderr] (http-/10.4.133.80:8080-1)  at javax.xml.ws.Service.&lt;init&gt;(Service.java:57)\n23:50:02,807
  ERROR [stderr] (http-/10.4.133.80:8080-1)  at com.aaa.ws.core.CoreService.&lt;init&gt;(CoreService.java:42)\n</code></pre>\n\n<p>The
  problem is this error does not happen on my local window machine (it is working
  well), but only happens on our linux server. This means the service name exists
  in the wsdl file. \nJBoss version is the same, and deployed the same war. \nI really
  don''t get what the cause of this issue is. \nWould be very gratefull for any help!</p>\n","user_id":"4393263","sys_created":"1484284538000","is_answered":"false","view_count":"5","up_vote_count":"0"},"sort":[1484284538000,1.0]},{"_index":"data_stackoverflow_question","_type":"stackoverflow_question","_id":"41626284","_score":1.0,"_source":{"source":"stackoverflow_question","space_key":"openshift-cartridge","sys_id":"41626284","sys_type":"stackoverflow_thread","answer_count":"0","sys_updated":"2017-01-12T22:34:01.326-05:00","sys_id":"stackoverflow_question-41626284","sys_url_view":"http://stackoverflow.com/questions/41626284/multichain-and-openshift","sys_content_id":"41626284","last_activity":"1484273002000","down_vote_count":"0","sys_content_provider":"stackoverflow","sys_content_content-type":"text/plain","owner":{"profile_image":"https://www.gravatar.com/avatar/44dd9ba4fbeae4a87465427e0a444441?s=128&d=identicon&r=PG&f=1","user_type":"registered","user_id":931742,"link":"http://stackoverflow.com/users/931742/kendall","reputation":691,"display_name":"Kendall","accept_rate":40},"sys_content_plaintext":"I''m
  currently experimenting with multichain and was wondering if open shift would be
  able to host the software. For it to work I''ll need to run shell commands and network
  multiple instances. Can open shift accommodate this?","sys_content_type":"stackoverflow_question","author":"Kendall-931742","sys_tags":["openshift","openshift-client-tools","openshift-cartridge"],"sys_title":"Stubbed
  Title Eight","tags":["openshift","openshift-client-tools","openshift-cartridge"],"sys_content":"<p>I''m
  currently experimenting with <a href=\"http://multichain.com\" rel=\"nofollow noreferrer\">multichain</a>
  and was wondering if open shift would be able to host the software. For it to work
  I''ll need to run shell commands and network multiple instances.</p>\n\n<p>Can open
  shift accommodate this?</p>\n","user_id":"931742","sys_created":"1484273002000","is_answered":"false","view_count":"5","up_vote_count":"0"},"sort":[1484273002000,1.0]},{"_index":"data_stackoverflow_question","_type":"stackoverflow_question","_id":"41625688","_score":1.0,"_source":{"source":"stackoverflow_question","space_key":"jboss","sys_id":"41625688","sys_type":"stackoverflow_thread","answer_count":"0","sys_updated":"2017-01-12T21:27:39.555-05:00","sys_id":"stackoverflow_question-41625688","sys_url_view":"http://stackoverflow.com/questions/41625688/securing-activemq-on-wildfly-10","sys_content_id":"41625688","last_activity":"1484268601000","down_vote_count":"0","sys_content_provider":"stackoverflow","sys_content_content-type":"text/plain","owner":{"profile_image":"https://www.gravatar.com/avatar/69c42a1546aa532142ef88253e39c38a?s=128&d=identicon&r=PG&f=1","user_type":"registered","user_id":7412423,"link":"http://stackoverflow.com/users/7412423/mevans7","reputation":1,"display_name":"mevans7"},"sys_content_plaintext":"I''m
  trying to configure the messaging-activemq subsystem to use https instead of http
  (to completely eliminate use of http). I''ve read: https://access.redhat.com/documentation/en/red-hat-jboss-enterprise-application-platform/7.0/single/configuring-messaging/#securing-remote-connections-jms-server
  In the Wildfly configuration file, the messaging-activemq subsystem, I''ve updated
  the http-connector, http-connector-throughput, http-acceptor, and http-acceptor-throughput
  to use https. The Wildfly server starts up without errors. However, when I try to
  connect from a client, I get client errors like \"javax.jms.JMSException: Failed
  to create session factory\". And at the server, I get messages like \"UT005013:
  An IOException occurred: javax.net.ssl.SSLException: Unrecognized SSL message, plaintext
  connection?\". I''ve searched RedHat and JBoss documentation (and more) and have
  not found a solution to how to configure the client and connection to talk to the
  Wildfly 10 activemq using https . Server configuration: (http-listener removed from
  undertow, http-listener attributes of http-acceptor changed from \"default\" to
  \"https\", socket-bindings in http-acceptor(s) changed to \"https\") <subsystem
  xmlns=\"urn:jboss:domain:messaging-activemq:1.0\"> <server name=\"default\"> <security
  enabled=\"false\"/> <security-setting name=\"#\"> <role name=\"guest\" delete-non-durable-queue=\"true\"
  create-non-durable-queue=\"true\" consume=\"true\" send=\"true\"/> </security-setting>
  <address-setting name=\"#\" message-counter-history-day-limit=\"10\" page-size-bytes=\"2097152\"
  max-size-bytes=\"10485760\" expiry-address=\"jms.queue.ExpiryQueue\" dead-letter-address=\"jms.queue.DLQ\"/>
  <http-connector name=\"http-connector\" endpoint=\"http-acceptor\" socket-binding=\"https\"/>
  <http-connector name=\"http-connector-throughput\" endpoint=\"http-acceptor-throughput\"
  socket-binding=\"https\"> <param name=\"batch-delay\" value=\"50\"/> </http-connector>
  <in-vm-connector name=\"in-vm\" server-id=\"0\"/> <http-acceptor name=\"http-acceptor\"
  http-listener=\"https\"/> <http-acceptor name=\"http-acceptor-throughput\" http-listener=\"https\">
  <param name=\"batch-delay\" value=\"50\"/> <param name=\"direct-deliver\" value=\"false\"/>
  </http-acceptor> <in-vm-acceptor name=\"in-vm\" server-id=\"0\"/> <jms-queue name=\"ExpiryQueue\"
  entries=\"java:/jms/queue/ExpiryQueue\"/> <jms-queue name=\"DLQ\" entries=\"java:/jms/queue/DLQ\"/>
  <connection-factory name=\"InVmConnectionFactory\" entries=\"java:/ConnectionFactory\"
  connectors=\"in-vm\"/> <connection-factory name=\"RemoteConnectionFactory\" consumer-window-size=\"0\"
  entries=\"java:jboss/exported/jms/RemoteConnectionFactory\" connectors=\"http-connector\"/>
  <pooled-connection-factory name=\"activemq-ra\" transaction=\"xa\" entries=\"java:/JmsXA
  java:jboss/DefaultJMSConnectionFactory\" connectors=\"in-vm\"/> </server> </subsystem>
  More server configuration: <subsystem xmlns=\"urn:jboss:domain:undertow:3.0\"> <buffer-cache
  name=\"default\"/> <server name=\"default-server\"> (REMOVED THIS) <http-listener
  name=\"default\" max-post-size=\"104857600\" socket-binding=\"http\" redirect-socket=\"https\"/>
  (REMOVED THIS) <https-listener name=\"https\" max-post-size=\"104857600\" security-realm=\"BISRealm\"
  socket-binding=\"https\"/> <host name=\"default-host\" alias=\"localhost\"/> </server>
  <servlet-container name=\"default\"> <jsp-config display-source-fragment=\"false\"/>
  <websockets/> </servlet-container> </subsystem> Server error message when client
  attempts to connect: 2017-01-12 14:03:47,283 DEBUG [io.undertow.request] (default
  I/O-11) UT005013: An IOException occurred: javax.net.ssl.SSLException: Unrecognized
  SSL message, plaintext connection? at sun.security.ssl.EngineInputRecord.bytesInCompletePacket(EngineInputRecord.java:156)
  [jsse.jar:1.8.0_71] at sun.security.ssl.SSLEngineImpl.readNetRecord(SSLEngineImpl.java:868)
  [jsse.jar:1.8.0_71] at sun.security.ssl.SSLEngineImpl.unwrap(SSLEngineImpl.java:781)
  [jsse.jar:1.8.0_71] at javax.net.ssl.SSLEngine.unwrap(SSLEngine.java:624) [rt.jar:1.8.0_71]
  at io.undertow.protocols.ssl.SslConduit.doUnwrap(SslConduit.java:705) at io.undertow.protocols.ssl.SslConduit.doHandshake(SslConduit.java:608)
  at io.undertow.protocols.ssl.SslConduit.access$600(SslConduit.java:63) at io.undertow.protocols.ssl.SslConduit$SslReadReadyHandler.readReady(SslConduit.java:1034)
  at org.xnio.nio.NioSocketConduit.handleReady(NioSocketConduit.java:88) [xnio-nio-3.3.4.Final.jar:3.3.4.Final]
  at org.xnio.nio.WorkerThread.run(WorkerThread.java:559) [xnio-nio-3.3.4.Final.jar:3.3.4.Final]
  2017-01-12 14:03:47,284 DEBUG [io.undertow.request.io] (default I/O-11) UT005013:
  An IOException occurred: java.io.IOException: javax.net.ssl.SSLException: Inbound
  closed before receiving peer''s close_notify: possible truncation attack? at io.undertow.protocols.ssl.SslConduit.notifyReadClosed(SslConduit.java:577)
  at io.undertow.protocols.ssl.SslConduit.doUnwrap(SslConduit.java:668) at io.undertow.protocols.ssl.SslConduit.read(SslConduit.java:530)
  at org.xnio.conduits.ConduitStreamSourceChannel.read(ConduitStreamSourceChannel.java:127)
  [xnio-api-3.3.4.Final.jar:3.3.4.Final] at io.undertow.server.protocol.http.HttpReadListener.handleEventWithNoRunningRequest(HttpReadListener.java:152)
  at io.undertow.server.protocol.http.HttpReadListener.handleEvent(HttpReadListener.java:130)
  at io.undertow.server.protocol.http.HttpReadListener.handleEvent(HttpReadListener.java:56)
  at org.xnio.ChannelListeners.invokeChannelListener(ChannelListeners.java:92) [xnio-api-3.3.4.Final.jar:3.3.4.Final]
  at org.xnio.conduits.ReadReadyHandler$ChannelListenerHandler.readReady(ReadReadyHandler.java:66)
  [xnio-api-3.3.4.Final.jar:3.3.4.Final] at io.undertow.protocols.ssl.SslConduit$SslReadReadyHandler.readReady(SslConduit.java:1059)
  at org.xnio.nio.NioSocketConduit.handleReady(NioSocketConduit.java:88) [xnio-nio-3.3.4.Final.jar:3.3.4.Final]
  at org.xnio.nio.WorkerThread.run(WorkerThread.java:559) [xnio-nio-3.3.4.Final.jar:3.3.4.Final]
  Caused by: javax.net.ssl.SSLException: Inbound closed before receiving peer''s close_notify:
  possible truncation attack? at sun.security.ssl.Alerts.getSSLException(Alerts.java:208)
  [jsse.jar:1.8.0_71] at sun.security.ssl.SSLEngineImpl.fatal(SSLEngineImpl.java:1666)
  [jsse.jar:1.8.0_71] at sun.security.ssl.SSLEngineImpl.fatal(SSLEngineImpl.java:1634)
  [jsse.jar:1.8.0_71] at sun.security.ssl.SSLEngineImpl.closeInbound(SSLEngineImpl.java:1561)
  [jsse.jar:1.8.0_71] at io.undertow.protocols.ssl.SslConduit.notifyReadClosed(SslConduit.java:575)
  ... 11 more Client error message when client attempts to read JMS message: 2017-01-12
  16:09:19.601 DEBUG org.apache.activemq.artemis.core.client.getConnectionWithRetry(750))
  #() #() Trying reconnection attempt 0/1 2017-01-12 16:09:19.601 DEBUG org.apache.activemq.artemis.core.client.createTransportConnection(1025))
  #() #() Trying to connect with connector = org.apache.activemq.artemis.core.remoting.impl.netty.NettyConnectorFactory@2714d74c,
  parameters = {httpUpgradeEnabled=true, port=8443, httpPpgradeEndpoint=http-acceptor,
  host=bisdb} connector = null 2017-01-12 16:09:19.601 DEBUG org.apache.activemq.artemis.core.client.start(528))
  #() #() Started Netty Connector version 4.0.32.Final 2017-01-12 16:09:19.602 DEBUG
  org.apache.activemq.artemis.core.client.createConnection(586)) #() #() Remote destination:
  bisdb/10.134.141.92:8443 2017-01-12 16:09:19.604 DEBUG org.apache.activemq.artemis.core.client.createConnection(656))
  #() #() Sending HTTP request DefaultHttpRequest(decodeResult: success, version:
  HTTP/1.1) GET HTTP/1.1 Host: bisdb Upgrade: activemq-remoting Connection: Upgrade
  httpPpgradeEndpoint: http-acceptor Sec-ActiveMQRemoting-Key: EVEoDiZ+Sv4Xe8QYk9X4PQ==
  2017-01-12 16:09:25.311 DEBUG org.jboss.ejb.client.EJBClientContext.getEJBReceiver(758))
  #() #() org.jboss.ejb.client.RandomDeploymentNodeSelector@d536e70 deployment node
  selector selected bisdb node for appname=MorphoBIS,modulename=Wfm,distinctname=
  2017-01-12 16:09:25.311 DEBUG org.jboss.ejb.client.ReceiverInterceptor.handleInvocation(136))
  #() #() Sending invocation to node bisdb 2017-01-12 16:09:35.318 DEBUG org.jboss.ejb.client.EJBClientContext.getEJBReceiver(758))
  #() #() org.jboss.ejb.client.RandomDeploymentNodeSelector@d536e70 deployment node
  selector selected bisdb node for appname=MorphoBIS,modulename=Wfm,distinctname=
  2017-01-12 16:09:35.318 DEBUG org.jboss.ejb.client.ReceiverInterceptor.handleInvocation(136))
  #() #() Sending invocation to node bisdb 2017-01-12 16:09:45.321 DEBUG org.jboss.ejb.client.EJBClientContext.getEJBReceiver(758))
  #() #() org.jboss.ejb.client.RandomDeploymentNodeSelector@d536e70 deployment node
  selector selected bisdb node for appname=MorphoBIS,modulename=Wfm,distinctname=
  2017-01-12 16:09:45.321 DEBUG org.jboss.ejb.client.ReceiverInterceptor.handleInvocation(136))
  #() #() Sending invocation to node bisdb 2017-01-12 16:09:49.604 DEBUG org.apache.activemq.artemis.core.client.openTransportConnection(994))
  #() #() Connector towards NettyConnector [host=bisdb, port=8443, httpEnabled=false,
  httpUpgradeEnabled=true, useServlet=false, servletPath=/messaging/ActiveMQServlet,
  sslEnabled=false, useNio=true] failed 2017-01-12 16:09:49.605 WARN Received exception
  jndiEnv : {java.naming.provider.url=https-remoting://bisapp:8443, java.naming.factory.initial=org.jboss.naming.remote.client.InitialContextFactory,
  UrlPkgPrefixes=org.jboss.naming:org.jnp.interfaces} javax.jms.JMSException: Failed
  to create session factory at org.apache.activemq.artemis.jms.client.ActiveMQConnectionFactory.createConnectionInternal(ActiveMQConnectionFactory.java:727)
  ~[jboss-client.jar:10.0.0.Final] at org.apache.activemq.artemis.jms.client.ActiveMQConnectionFactory.createQueueConnection(ActiveMQConnectionFactory.java:284)
  ~[jboss-client.jar:10.0.0.Final] at org.apache.activemq.artemis.jms.client.ActiveMQConnectionFactory.createQueueConnection(ActiveMQConnectionFactory.java:280)
  ~[jboss-client.jar:10.0.0.Final] ... at java.lang.Thread.run(Thread.java:745) [na:1.8.0_71]
  Caused by: org.apache.activemq.artemis.api.core.ActiveMQNotConnectedException: AMQ119007:
  Cannot connect to server(s). Tried with all available servers. at org.apache.activemq.artemis.core.client.impl.ServerLocatorImpl.createSessionFactory(ServerLocatorImpl.java:777)
  ~[jboss-client.jar:10.0.0.Final] at org.apache.activemq.artemis.jms.client.ActiveMQConnectionFactory.createConnectionInternal(ActiveMQConnectionFactory.java:724)
  ~[jboss-client.jar:10.0.0.Final] ... 10 common frames omitted It looks like the
  client is attempting to communicate via HTTP but I cannot figure out how to configure
  the connection to use HTTPS. How do I configure the Wildfly 10 server (and clients)
  to use messaging-activemq over https?","sys_content_type":"stackoverflow_question","author":"mevans7-7412423","sys_tags":["ssl","https","jboss","activemq","wildfly"],"sys_title":"Stubbed
  Title Nine","tags":["ssl","https","jboss","activemq","wildfly"],"sys_content":"<p>I''m
  trying to configure the <strong>messaging-activemq</strong> subsystem to use <strong>https</strong>
  instead of http (to completely eliminate use of http).  </p>\n\n<p>I''ve read: <a
  href=\"https://access.redhat.com/documentation/en/red-hat-jboss-enterprise-application-platform/7.0/single/configuring-messaging/#securing-remote-connections-jms-server\"
  rel=\"nofollow noreferrer\">https://access.redhat.com/documentation/en/red-hat-jboss-enterprise-application-platform/7.0/single/configuring-messaging/#securing-remote-connections-jms-server</a></p>\n\n<p>In
  the Wildfly configuration file, the messaging-activemq subsystem, I''ve updated
  the http-connector, http-connector-throughput, http-acceptor, and http-acceptor-throughput
  to use https.  The Wildfly server starts up without errors.  However, when I try
  to connect from a client, I get client errors like \"javax.jms.JMSException: Failed
  to create session factory\".  And at the server, I get messages like \"UT005013:
  An IOException occurred: javax.net.ssl.SSLException: Unrecognized SSL message, plaintext
  connection?\".</p>\n\n<p>I''ve searched RedHat and JBoss documentation (and more)
  and have not found a solution to how to configure the client and connection to talk
  to the Wildfly 10 activemq using <strong>https</strong>.</p>\n\n<p>Server configuration:</p>\n\n<p>(http-listener
  removed from undertow, http-listener attributes of http-acceptor changed from \"default\"
  to \"https\", socket-bindings in http-acceptor(s) changed to \"https\")</p>\n\n<pre><code>    &lt;subsystem
  xmlns=\"urn:jboss:domain:messaging-activemq:1.0\"&gt;\n        &lt;server name=\"default\"&gt;\n            &lt;security
  enabled=\"false\"/&gt;\n            &lt;security-setting name=\"#\"&gt;\n                &lt;role
  name=\"guest\" delete-non-durable-queue=\"true\" create-non-durable-queue=\"true\"
  consume=\"true\" send=\"true\"/&gt;\n            &lt;/security-setting&gt;\n            &lt;address-setting
  name=\"#\" message-counter-history-day-limit=\"10\" page-size-bytes=\"2097152\"
  max-size-bytes=\"10485760\" expiry-address=\"jms.queue.ExpiryQueue\" dead-letter-address=\"jms.queue.DLQ\"/&gt;\n            &lt;http-connector
  name=\"http-connector\" endpoint=\"http-acceptor\" socket-binding=\"https\"/&gt;\n            &lt;http-connector
  name=\"http-connector-throughput\" endpoint=\"http-acceptor-throughput\" socket-binding=\"https\"&gt;\n                &lt;param
  name=\"batch-delay\" value=\"50\"/&gt;\n            &lt;/http-connector&gt;\n            &lt;in-vm-connector
  name=\"in-vm\" server-id=\"0\"/&gt;\n            &lt;http-acceptor name=\"http-acceptor\"
  http-listener=\"https\"/&gt;\n            &lt;http-acceptor name=\"http-acceptor-throughput\"
  http-listener=\"https\"&gt;\n                &lt;param name=\"batch-delay\" value=\"50\"/&gt;\n                &lt;param
  name=\"direct-deliver\" value=\"false\"/&gt;\n            &lt;/http-acceptor&gt;\n            &lt;in-vm-acceptor
  name=\"in-vm\" server-id=\"0\"/&gt;\n            &lt;jms-queue name=\"ExpiryQueue\"
  entries=\"java:/jms/queue/ExpiryQueue\"/&gt;\n            &lt;jms-queue name=\"DLQ\"
  entries=\"java:/jms/queue/DLQ\"/&gt;\n            &lt;connection-factory name=\"InVmConnectionFactory\"
  entries=\"java:/ConnectionFactory\" connectors=\"in-vm\"/&gt;\n            &lt;connection-factory
  name=\"RemoteConnectionFactory\" consumer-window-size=\"0\" entries=\"java:jboss/exported/jms/RemoteConnectionFactory\"
  connectors=\"http-connector\"/&gt;\n            &lt;pooled-connection-factory name=\"activemq-ra\"
  transaction=\"xa\" entries=\"java:/JmsXA java:jboss/DefaultJMSConnectionFactory\"
  connectors=\"in-vm\"/&gt;\n        &lt;/server&gt;\n    &lt;/subsystem&gt;\n</code></pre>\n\n<p>More
  server configuration:</p>\n\n<pre><code>    &lt;subsystem xmlns=\"urn:jboss:domain:undertow:3.0\"&gt;\n        &lt;buffer-cache
  name=\"default\"/&gt;\n        &lt;server name=\"default-server\"&gt;\n            (REMOVED
  THIS) &lt;http-listener name=\"default\" max-post-size=\"104857600\" socket-binding=\"http\"
  redirect-socket=\"https\"/&gt; (REMOVED THIS)\n\n            &lt;https-listener
  name=\"https\" max-post-size=\"104857600\" security-realm=\"BISRealm\" socket-binding=\"https\"/&gt;\n            &lt;host
  name=\"default-host\" alias=\"localhost\"/&gt;\n        &lt;/server&gt;\n        &lt;servlet-container
  name=\"default\"&gt;\n            &lt;jsp-config display-source-fragment=\"false\"/&gt;\n            &lt;websockets/&gt;\n        &lt;/servlet-container&gt;\n    &lt;/subsystem&gt;\n</code></pre>\n\n<p>Server
  error message when client attempts to connect:</p>\n\n<pre><code>2017-01-12 14:03:47,283
  DEBUG [io.undertow.request] (default I/O-11) UT005013: An IOException occurred:
  javax.net.ssl.SSLException: Unrecognized SSL message, plaintext connection?\n        at
  sun.security.ssl.EngineInputRecord.bytesInCompletePacket(EngineInputRecord.java:156)
  [jsse.jar:1.8.0_71]\n        at sun.security.ssl.SSLEngineImpl.readNetRecord(SSLEngineImpl.java:868)
  [jsse.jar:1.8.0_71]\n        at sun.security.ssl.SSLEngineImpl.unwrap(SSLEngineImpl.java:781)
  [jsse.jar:1.8.0_71]\n        at javax.net.ssl.SSLEngine.unwrap(SSLEngine.java:624)
  [rt.jar:1.8.0_71]\n        at io.undertow.protocols.ssl.SslConduit.doUnwrap(SslConduit.java:705)\n        at
  io.undertow.protocols.ssl.SslConduit.doHandshake(SslConduit.java:608)\n        at
  io.undertow.protocols.ssl.SslConduit.access$600(SslConduit.java:63)\n        at
  io.undertow.protocols.ssl.SslConduit$SslReadReadyHandler.readReady(SslConduit.java:1034)\n        at
  org.xnio.nio.NioSocketConduit.handleReady(NioSocketConduit.java:88) [xnio-nio-3.3.4.Final.jar:3.3.4.Final]\n        at
  org.xnio.nio.WorkerThread.run(WorkerThread.java:559) [xnio-nio-3.3.4.Final.jar:3.3.4.Final]\n\n2017-01-12
  14:03:47,284 DEBUG [io.undertow.request.io] (default I/O-11) UT005013: An IOException
  occurred: java.io.IOException: javax.net.ssl.SSLException: Inbound closed before
  receiving peer''s close_notify: possible truncation attack?\n        at io.undertow.protocols.ssl.SslConduit.notifyReadClosed(SslConduit.java:577)\n        at
  io.undertow.protocols.ssl.SslConduit.doUnwrap(SslConduit.java:668)\n        at io.undertow.protocols.ssl.SslConduit.read(SslConduit.java:530)\n        at
  org.xnio.conduits.ConduitStreamSourceChannel.read(ConduitStreamSourceChannel.java:127)
  [xnio-api-3.3.4.Final.jar:3.3.4.Final]\n        at io.undertow.server.protocol.http.HttpReadListener.handleEventWithNoRunningRequest(HttpReadListener.java:152)\n        at
  io.undertow.server.protocol.http.HttpReadListener.handleEvent(HttpReadListener.java:130)\n        at
  io.undertow.server.protocol.http.HttpReadListener.handleEvent(HttpReadListener.java:56)\n        at
  org.xnio.ChannelListeners.invokeChannelListener(ChannelListeners.java:92) [xnio-api-3.3.4.Final.jar:3.3.4.Final]\n        at
  org.xnio.conduits.ReadReadyHandler$ChannelListenerHandler.readReady(ReadReadyHandler.java:66)
  [xnio-api-3.3.4.Final.jar:3.3.4.Final]\n        at io.undertow.protocols.ssl.SslConduit$SslReadReadyHandler.readReady(SslConduit.java:1059)\n        at
  org.xnio.nio.NioSocketConduit.handleReady(NioSocketConduit.java:88) [xnio-nio-3.3.4.Final.jar:3.3.4.Final]\n        at
  org.xnio.nio.WorkerThread.run(WorkerThread.java:559) [xnio-nio-3.3.4.Final.jar:3.3.4.Final]\nCaused
  by: javax.net.ssl.SSLException: Inbound closed before receiving peer''s close_notify:
  possible truncation attack?\n        at sun.security.ssl.Alerts.getSSLException(Alerts.java:208)
  [jsse.jar:1.8.0_71]\n        at sun.security.ssl.SSLEngineImpl.fatal(SSLEngineImpl.java:1666)
  [jsse.jar:1.8.0_71]\n        at sun.security.ssl.SSLEngineImpl.fatal(SSLEngineImpl.java:1634)
  [jsse.jar:1.8.0_71]\n        at sun.security.ssl.SSLEngineImpl.closeInbound(SSLEngineImpl.java:1561)
  [jsse.jar:1.8.0_71]\n        at io.undertow.protocols.ssl.SslConduit.notifyReadClosed(SslConduit.java:575)\n        ...
  11 more\n</code></pre>\n\n<p>Client error message when client attempts to read JMS
  message:</p>\n\n<pre><code>2017-01-12 16:09:19.601   DEBUG  org.apache.activemq.artemis.core.client.getConnectionWithRetry(750))
  #() #() Trying reconnection attempt 0/1\n2017-01-12 16:09:19.601   DEBUG  org.apache.activemq.artemis.core.client.createTransportConnection(1025))
  #() #() Trying to connect with connector = org.apache.activemq.artemis.core.remoting.impl.netty.NettyConnectorFactory@2714d74c,
  parameters = {httpUpgradeEnabled=true, port=8443, httpPpgradeEndpoint=http-acceptor,
  host=bisdb} connector = null\n2017-01-12 16:09:19.601   DEBUG  org.apache.activemq.artemis.core.client.start(528))
  #() #() Started Netty Connector version 4.0.32.Final\n2017-01-12 16:09:19.602   DEBUG  org.apache.activemq.artemis.core.client.createConnection(586))
  #() #() Remote destination: bisdb/10.134.141.92:8443\n2017-01-12 16:09:19.604   DEBUG  org.apache.activemq.artemis.core.client.createConnection(656))
  #() #() Sending HTTP request DefaultHttpRequest(decodeResult: success, version:
  HTTP/1.1)\nGET  HTTP/1.1\nHost: bisdb\nUpgrade: activemq-remoting\nConnection: Upgrade\nhttpPpgradeEndpoint:
  http-acceptor\nSec-ActiveMQRemoting-Key: EVEoDiZ+Sv4Xe8QYk9X4PQ==\n2017-01-12 16:09:25.311   DEBUG  org.jboss.ejb.client.EJBClientContext.getEJBReceiver(758))
  #() #() org.jboss.ejb.client.RandomDeploymentNodeSelector@d536e70 deployment node
  selector selected bisdb node for appname=MorphoBIS,modulename=Wfm,distinctname=\n2017-01-12
  16:09:25.311   DEBUG  org.jboss.ejb.client.ReceiverInterceptor.handleInvocation(136))
  #() #() Sending invocation to node bisdb\n2017-01-12 16:09:35.318   DEBUG  org.jboss.ejb.client.EJBClientContext.getEJBReceiver(758))
  #() #() org.jboss.ejb.client.RandomDeploymentNodeSelector@d536e70 deployment node
  selector selected bisdb node for appname=MorphoBIS,modulename=Wfm,distinctname=\n2017-01-12
  16:09:35.318   DEBUG  org.jboss.ejb.client.ReceiverInterceptor.handleInvocation(136))
  #() #() Sending invocation to node bisdb\n2017-01-12 16:09:45.321   DEBUG  org.jboss.ejb.client.EJBClientContext.getEJBReceiver(758))
  #() #() org.jboss.ejb.client.RandomDeploymentNodeSelector@d536e70 deployment node
  selector selected bisdb node for appname=MorphoBIS,modulename=Wfm,distinctname=\n2017-01-12
  16:09:45.321   DEBUG  org.jboss.ejb.client.ReceiverInterceptor.handleInvocation(136))
  #() #() Sending invocation to node bisdb\n2017-01-12 16:09:49.604   DEBUG  org.apache.activemq.artemis.core.client.openTransportConnection(994))
  #() #() Connector towards NettyConnector [host=bisdb, port=8443, httpEnabled=false,
  httpUpgradeEnabled=true, useServlet=false, servletPath=/messaging/ActiveMQServlet,
  sslEnabled=false, useNio=true] failed\n2017-01-12 16:09:49.605   WARN   Received
  exception jndiEnv  : {java.naming.provider.url=https-remoting://bisapp:8443, java.naming.factory.initial=org.jboss.naming.remote.client.InitialContextFactory,
  UrlPkgPrefixes=org.jboss.naming:org.jnp.interfaces}\njavax.jms.JMSException: Failed
  to create session factory\n        at org.apache.activemq.artemis.jms.client.ActiveMQConnectionFactory.createConnectionInternal(ActiveMQConnectionFactory.java:727)
  ~[jboss-client.jar:10.0.0.Final]\n        at org.apache.activemq.artemis.jms.client.ActiveMQConnectionFactory.createQueueConnection(ActiveMQConnectionFactory.java:284)
  ~[jboss-client.jar:10.0.0.Final]\n        at org.apache.activemq.artemis.jms.client.ActiveMQConnectionFactory.createQueueConnection(ActiveMQConnectionFactory.java:280)
  ~[jboss-client.jar:10.0.0.Final]\n...\n        at java.lang.Thread.run(Thread.java:745)
  [na:1.8.0_71]\nCaused by: org.apache.activemq.artemis.api.core.ActiveMQNotConnectedException:
  AMQ119007: Cannot connect to server(s). Tried with all available servers.\n        at
  org.apache.activemq.artemis.core.client.impl.ServerLocatorImpl.createSessionFactory(ServerLocatorImpl.java:777)
  ~[jboss-client.jar:10.0.0.Final]\n        at org.apache.activemq.artemis.jms.client.ActiveMQConnectionFactory.createConnectionInternal(ActiveMQConnectionFactory.java:724)
  ~[jboss-client.jar:10.0.0.Final]\n        ... 10 common frames omitted\n</code></pre>\n\n<p>It
  looks like the client is attempting to communicate via HTTP but I cannot figure
  out how to configure the connection to use HTTPS.</p>\n\n<p>How do I configure the
  Wildfly 10 server (and clients) to use messaging-activemq over https?</p>\n","user_id":"7412423","sys_created":"1484268601000","is_answered":"false","view_count":"3","up_vote_count":"0"},"sort":[1484268601000,1.0]},{"_index":"data_stackoverflow_question","_type":"stackoverflow_question","_id":"41621801","_score":1.0,"_source":{"source":"stackoverflow_question","space_key":"jboss","sys_id":"41621801","sys_type":"stackoverflow_thread","answer_count":"0","sys_updated":"2017-01-12T16:27:08.484-05:00","sys_id":"stackoverflow_question-41621801","sys_url_view":"http://stackoverflow.com/questions/41621801/how-to-have-azure-app-service-tomcat-to-forward-all-80-443-traffic-to-jboss-runn","sys_content_id":"41621801","last_activity":"1484256156000","down_vote_count":"0","sys_content_provider":"stackoverflow","sys_content_content-type":"text/plain","owner":{"profile_image":"https://www.gravatar.com/avatar/446d3b487ffbd53403274bb565286b07?s=128&d=identicon&r=PG","user_type":"registered","user_id":1159139,"link":"http://stackoverflow.com/users/1159139/kirill-yunussov","reputation":339,"display_name":"Kirill
  Yunussov","accept_rate":67},"sys_content_plaintext":"First of all, my Azure subscription
  is through a Cloud Service Provider, so I don''t have access to certain features
  (i.e. cannot install a marketplace tomcat, only the native one; with the native
  Tomcat I do not have access to server.xml, which I need for some traffic rerouting
  solutions - modifying Connectors). The basic need is to have IBM''s B2B Client app
  running and sending files back and forth. It comes with its own JBoss, and all you
  do is put the app in a directory on Azure App Service and run the executable. This
  is already not a problem, and I have it starting with the app service using a WebJob.
  Problem: App Service only has two inbound ports open - 80 and 443, and they are
  both being used by Tomcat. So I need to either: 1) Disable Tomcat, and only have
  JBoss running and listening on those ports without conflicts; or 2) Have native
  Tomcat forward traffic to JBoss. How can I do either of those in this environment,
  and are there better solutions for this problem?","sys_content_type":"stackoverflow_question","comments":[{"owner":{"profile_image":"https://www.gravatar.com/avatar/32170c62eb744820e8afdd023379a95a?s=128&d=identicon&r=PG","user_type":"registered","user_id":272109,"link":"http://stackoverflow.com/users/272109/david-makogon","reputation":45073,"display_name":"David
  Makogon"},"score":0,"post_id":41621801,"edited":false,"creation_date":"1484255416000","comment_id":70447452},{"owner":{"profile_image":"https://www.gravatar.com/avatar/446d3b487ffbd53403274bb565286b07?s=128&d=identicon&r=PG","user_type":"registered","user_id":1159139,"link":"http://stackoverflow.com/users/1159139/kirill-yunussov","reputation":339,"display_name":"Kirill
  Yunussov","accept_rate":67},"score":0,"post_id":41621801,"reply_to_user":{"profile_image":"https://www.gravatar.com/avatar/32170c62eb744820e8afdd023379a95a?s=128&d=identicon&r=PG","user_type":"registered","user_id":272109,"link":"http://stackoverflow.com/users/272109/david-makogon","reputation":45073,"display_name":"David
  Makogon"},"edited":false,"creation_date":"1484255924000","comment_id":70447748}],"author":"Kirill
  Yunussov-1159139","sys_tags":["java","azure","tomcat","jboss","b2b"],"sys_title":"Stubbed
  Title Ten","tags":["java","azure","tomcat","jboss","b2b"],"sys_content":"<p>First
  of all, my Azure subscription is through a Cloud Service Provider, so I don''t have
  access to certain features (i.e. cannot install a marketplace tomcat, only the native
  one; with the native Tomcat I do not have access to server.xml, which I need for
  some traffic rerouting solutions - modifying Connectors).</p>\n\n<p>The basic need
  is to have IBM''s B2B Client app running and sending files back and forth.  It comes
  with its own JBoss, and all you do is put the app in a directory on Azure App Service
  and run the executable.  This is already not a problem, and I have it starting with
  the app service using a WebJob. </p>\n\n<p>Problem: \nApp Service only has two inbound
  ports open - 80 and 443, and they are both being used by Tomcat.  </p>\n\n<p>So
  I need to either:</p>\n\n<p>1) Disable Tomcat, and only have JBoss running and listening
  on those ports without conflicts;</p>\n\n<p>or</p>\n\n<p>2) Have native Tomcat forward
  traffic to JBoss.</p>\n\n<p>How can I do either of those in this environment, and
  are there better solutions for this problem?</p>\n","user_id":"1159139","sys_created":"1484250725000","is_answered":"false","view_count":"8","up_vote_count":"0"},"sort":[1484250725000,1.0]}]}}'
